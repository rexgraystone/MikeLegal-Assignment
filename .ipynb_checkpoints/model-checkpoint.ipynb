{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d00e5dc-0a44-4298-9168-0fd8bf2c3bf3",
   "metadata": {},
   "source": [
    "# Task - Generate Missing Clauses from Legal Contracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548e170-dfaa-403d-8612-6ac031a3a403",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a66899e-a664-42ea-a6c7-af854cfafd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import win32com.client as win32\n",
    "import PyPDF2\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd96dd-50f0-435b-83d0-1d2df5c47de2",
   "metadata": {},
   "source": [
    "Define the required paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a0b26a-e66f-420d-ab43-a85a6078ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../SampleDocs'\n",
    "testing_path = 'Testing'\n",
    "output_path = '../PDFs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c24b70-44f1-4169-a616-12ebf2979704",
   "metadata": {},
   "source": [
    "Function to save the .docx files to .pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07bed8e6-c006-47d1-939b-7d795ac185a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pdf(docx_path, pdf_path):\n",
    "    doc = Document(docx_path)\n",
    "    temp_doc_path = \"temp.doc\"\n",
    "    doc.save(temp_doc_path)\n",
    "    word = win32.Dispatch(\"Word.Application\")\n",
    "    try:\n",
    "        word.Visible = False\n",
    "        doc = word.Documents.Open(os.path.abspath(temp_doc_path))\n",
    "        doc.SaveAs(os.path.abspath(pdf_path), FileFormat=17)  # FileFormat 17 represents PDF\n",
    "    finally:\n",
    "        doc.Close()\n",
    "        word.Quit()\n",
    "    os.remove(temp_doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313e160-babc-4e3a-ae3d-882f3fbc5982",
   "metadata": {},
   "source": [
    "Function to read the text from .pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa58df7e-3c2d-4ed2-b4c0-ef3433409bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        extracted_text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            extracted_text += page.extract_text()\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee3a97-1b7c-4386-b390-90312512944e",
   "metadata": {},
   "source": [
    "Saving all the .docx files to .pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a13bae-685e-4f31-b73d-57a54eb776c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(os.listdir(input_path)):\n",
    "    if file.endswith('.docx'):\n",
    "        name = file[:-5]\n",
    "        name = f'{name}.pdf'\n",
    "        save_to_pdf(docx_path=f'{input_path}/{file}', pdf_path=f'{output_path}/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fba4154-3c4b-4b3c-8685-e5f0c7e3a5f0",
   "metadata": {},
   "source": [
    "Saving the testing files as .pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0373bcd7-4c81-410a-bf4d-e043b8e19843",
   "metadata": {},
   "outputs": [
    {
     "ename": "com_error",
     "evalue": "(-2147352567, 'Exception occurred.', (0, 'Microsoft Word', 'Command failed', 'wdmain11.chm', 36966, -2146824090), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mcom_error\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m name \u001b[38;5;241m=\u001b[39m file[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m      4\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43msave_to_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocx_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minput_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtesting_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moutput_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtesting_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36msave_to_pdf\u001b[1;34m(docx_path, pdf_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m     word\u001b[38;5;241m.\u001b[39mVisible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     doc \u001b[38;5;241m=\u001b[39m word\u001b[38;5;241m.\u001b[39mDocuments\u001b[38;5;241m.\u001b[39mOpen(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(temp_doc_path))\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSaveAs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFileFormat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# FileFormat 17 represents PDF\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     doc\u001b[38;5;241m.\u001b[39mClose()\n",
      "File \u001b[1;32m<COMObject Open>:5\u001b[0m, in \u001b[0;36mSaveAs\u001b[1;34m(self, FileName, FileFormat, LockComments, Password, AddToRecentFiles, WritePassword, ReadOnlyRecommended, EmbedTrueTypeFonts, SaveNativePictureFormat, SaveFormsData, SaveAsAOCELetter, Encoding, InsertLineBreaks, AllowSubstitutions, LineEnding, AddBiDiMarks)\u001b[0m\n",
      "\u001b[1;31mcom_error\u001b[0m: (-2147352567, 'Exception occurred.', (0, 'Microsoft Word', 'Command failed', 'wdmain11.chm', 36966, -2146824090), None)"
     ]
    }
   ],
   "source": [
    "for index, file in enumerate(os.listdir(f'{input_path}/{testing_path}')):\n",
    "    if file.endswith('.docx'):\n",
    "        name = file[:-5]\n",
    "        name = f'{name}.pdf'\n",
    "        save_to_pdf(docx_path=f'{input_path}/{testing_path}/{file}', pdf_path=f'{output_path}/{testing_path}/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f294f18-3f7c-4057-880c-1f2e827c888b",
   "metadata": {},
   "source": [
    "Initializing a blank dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59530ba3-0a83-4498-876e-4e0b570b68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Heading', 'Content'])\n",
    "test = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498abf36-05b8-49bc-ab6d-09a14a5f1f3b",
   "metadata": {},
   "source": [
    "Define the headings of the legal documents in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc15a2c-34bc-4225-87c5-cc3d9058f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = [\n",
    "    \"Employment Agreement\", \n",
    "    \"Investment Commitment Agreement\", \n",
    "    \"Consulting Agreement\", \n",
    "    \"Contract for the sale of goods\", \n",
    "    \"Joint Venture Agreement\",\n",
    "    \"Shareholder's Agreement\",\n",
    "    \"Shareholder's Agreement\",\n",
    "    \"Founders Agreement\", \n",
    "    \"Limited Liability Operating Agreement\",\n",
    "    \"Offer Letter Agreement\",\n",
    "    \"Collaboration Agreement\",\n",
    "    \"Rental Agreement\",\n",
    "    \"Sale Agreement\",\n",
    "    \"Agreement\"\n",
    "]\n",
    "\n",
    "test_headings = [\n",
    "    \"Joint Venture Agreement\",\n",
    "    \"Shareholder's Agreement\",\n",
    "    \"Founders Agreement\",\n",
    "    \"Sale Agreement\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236a6f8-74a9-4931-9b85-5b0a326fa5ec",
   "metadata": {},
   "source": [
    "Extract text from all the files and store it in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b3db7-9a9e-4f65-80ca-22c06914833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(os.listdir(output_path)):\n",
    "    if file.endswith('.pdf'):\n",
    "        row = []\n",
    "        content = read_text_from_pdf(f'{output_path}/{file}')\n",
    "        row = [headings[index], content]\n",
    "        df.loc[index] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14f17c-257b-4c94-8d30-62774a90bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(os.listdir(f'../{testing_path}')):\n",
    "    if file.endswith('.pdf'):\n",
    "        row = []\n",
    "        content = read_text_from_pdf(f'../{testing_path}/{file}')\n",
    "        row = [headings[index], content]\n",
    "        test.loc[index] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2775d2c7-a4d4-4181-9d1f-995953ace01b",
   "metadata": {},
   "source": [
    "Save the dataframes to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaaeaae-1331-4580-8019-7026428616c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de977229-0803-4547-98fd-52c012c2849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875cb38-3816-4e5f-bc84-e1a6796ab883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset.csv')\n",
    "test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6311fe-c8cb-4690-862b-6f5c27e0c133",
   "metadata": {},
   "source": [
    "Load the column 'contents' to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb7c48-602c-4155-baa6-9b7b990cfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = df['Content']\n",
    "test_content = test['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc56a28-73dc-478f-9f23-018cf0f1ac70",
   "metadata": {},
   "source": [
    "The clauses are defined in the form of (x) or x.y.z. where x, y, z are numbers.\n",
    "Therefore, the delimiters are defined as such with the required regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4eb05-46aa-44ec-83ed-f4d0fca669f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiters = [\n",
    "    r'\\(\\d+\\)',     \n",
    "    r'\\d+\\.\\d+\\.\\d+' \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8442f4-48bf-4d37-9771-94a765fbb6af",
   "metadata": {},
   "source": [
    "Function to extract the clauses from content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87fe10-3f89-4dfa-9bd1-bea714bf360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clauses(content):\n",
    "    clauses = []\n",
    "    current_clause = ''\n",
    "    for row in content:\n",
    "        for line in row.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if any(re.match(delimiter, line) for delimiter in delimiters):\n",
    "                if current_clause:\n",
    "                    clauses.append(current_clause.strip())\n",
    "                    current_clause = ''\n",
    "            current_clause += line + ' '\n",
    "        if current_clause:\n",
    "            clauses.append(current_clause.strip())\n",
    "    return clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2b242-97ed-4d7c-a2bd-f7bc7525de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clauses = get_clauses(content)\n",
    "test_clauses = get_clauses(test_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483e2ae-331f-46e1-b7b1-0cf8f98cd70e",
   "metadata": {},
   "source": [
    "Doc2Vec embeddings requires tagged documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d40f2f-7618-4b7a-ac8c-171764ade7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = {}\n",
    "for index, doc in enumerate(clauses):\n",
    "    key = f\"DOC_{index+1}\"\n",
    "    tagged[key] = TaggedDocument(words=doc, tags=[f\"DOC_{index+1}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d8a5b1-4108-4c1d-b459-906e084f3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for key in tagged:\n",
    "    docs.append(tagged[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd3619-7597-48e9-bdc8-76a6ec5cac26",
   "metadata": {},
   "source": [
    "Initializing a Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76fecd-a9cc-490e-8c74-770058587c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 300\n",
    "doc2vec = Doc2Vec(documents=docs, vector_size=dim, window=10, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcbc80-48ac-4a18-aca6-083e818f99c8",
   "metadata": {},
   "source": [
    "Saving the embeddings and creating an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917b5d8-453e-4a14-8f4b-66691de0b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = doc2vec.dv\n",
    "embeddings.save('embeddings')\n",
    "emb = embeddings.vectors\n",
    "embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(emb), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de57b0a3-8856-44c9-9cbb-0e2ca3ed0924",
   "metadata": {},
   "source": [
    "Initializing the GPT2-XL transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883120f-5428-4f88-8614-ceb9efb18510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-xl\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0562fce4-c924-4207-ba0b-f2a3f7f9d43f",
   "metadata": {},
   "source": [
    "Model structure before adding the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d9860e-afd2-4af8-94c1-5d83a198c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba423b91-1fea-4783-a604-4fe018d737b3",
   "metadata": {},
   "source": [
    "Model Structure after adding the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca8265-e923-47a7-b1cb-583ee0c6f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embeddings = embedding_layer\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a9aa4-712e-4974-aba1-affa7089c3ee",
   "metadata": {},
   "source": [
    "Initialize a custom dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562b6b5-33b7-4e03-a96d-ad21be9f8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.data[idx]\n",
    "        input_ids = self.tokenizer.encode(input_text, add_special_tokens=True)\n",
    "        return torch.tensor(input_ids[:-1]), torch.tensor(input_ids[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097db3d3-6d39-4a75-8fab-81d095fd0e4a",
   "metadata": {},
   "source": [
    "Create train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d0f2d-83f0-4308-b036-cd6ef7f720af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(clauses, tokenizer)\n",
    "valid_dataset = CustomDataset(test_clauses, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4e90c-c59b-4be7-90c0-e1b73c3c86fe",
   "metadata": {},
   "source": [
    "Set the device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653ec37-6796-4a5f-9309-3f080b94569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec35043d-cc98-485d-9bad-145166e2cfbb",
   "metadata": {},
   "source": [
    "Define the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa8178a-41e5-4439-b7c4-9f15a422b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5cf54c-02de-40b3-b6dd-6b6a3eb96c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(5):\n",
    "    for batch in train_loader:\n",
    "        input_ids, labels = batch[:1024]\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "        for batch in valid_loader:\n",
    "            input_ids, labels = batch[:1024]\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(input_ids, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item() * input_ids.size(0)\n",
    "            total_samples += input_ids.size(0)\n",
    "        avg_loss = total_loss / total_samples\n",
    "        print(f\"Validation Loss: {avg_loss}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8021feeb-fe63-4289-9c1f-0e7faabb3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./clause-model\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "25dcb6b4-ba20-4210-9fb8-5853f99a2c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(sample, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "51ae9ad9-122a-4610-80da-3216993840ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_new_tokens=max_new_tokens, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "80d67883-aedd-4293-a92b-6be31c22e03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOINT  VENTURE  AGREEMENT DATED 21 January  2018    BY AND BETWEEN    MIKELEGAL PRIVATE LIMITED   AND   MIKELEGAL SERVICES  LIMITED      TABLE OF CONTENTS 1. DEFINITIONS AND INTERPRETATION .........................................................................................  4 2. EFFECTIVE DATE .......................................................................................................................  13 3. INCORPORATION OF THE COMPANY .......................................................................................  13 4. COND ITIONS PRECEDENT .........................................................................................................  16 5. COMPLETION ...........................................................................................................................  17 6. CONDITIONS SUBSEQUENT ...................................................................................................... 18 7. CAPITAL COMMITMENT AND FUNDING ..................................................................................................  19 8. EXECUTIVE OFFICERS.......................................................................................  20 9. EXECUTIVE OFFICERS AND DIRECTORS.......................................................................................  21 10. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  22 11. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  23 12. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  24 13. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  25 14. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  26 15. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  27 16. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  28 17. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  29 18. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  30 19. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  31 20. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  32 21. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  33 22. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  34 23. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  35 24. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  36 25. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  37 26. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  38 27. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  39 28. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  40 29. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  41 30. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  42 31. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  43 32. EXECUTIVE OFFICERS AND DIRECTORS OF.......................................................................................  44 33. EXECUTIVE OFFICERS AND\n"
     ]
    }
   ],
   "source": [
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
