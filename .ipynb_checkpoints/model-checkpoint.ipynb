{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d00e5dc-0a44-4298-9168-0fd8bf2c3bf3",
   "metadata": {},
   "source": [
    "# Task - Generate Missing Clauses from Legal Contracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548e170-dfaa-403d-8612-6ac031a3a403",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a66899e-a664-42ea-a6c7-af854cfafd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import win32com.client as win32\n",
    "import PyPDF2\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd96dd-50f0-435b-83d0-1d2df5c47de2",
   "metadata": {},
   "source": [
    "Define the required paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a0b26a-e66f-420d-ab43-a85a6078ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../SampleDocs'\n",
    "testing_path = 'Testing'\n",
    "output_path = '../PDFs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c24b70-44f1-4169-a616-12ebf2979704",
   "metadata": {},
   "source": [
    "Function to save the .docx files to .pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07bed8e6-c006-47d1-939b-7d795ac185a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pdf(docx_path, pdf_path):\n",
    "    doc = Document(docx_path)\n",
    "    temp_doc_path = \"temp.doc\"\n",
    "    doc.save(temp_doc_path)\n",
    "    word = win32.Dispatch(\"Word.Application\")\n",
    "    try:\n",
    "        word.Visible = False\n",
    "        doc = word.Documents.Open(os.path.abspath(temp_doc_path))\n",
    "        doc.SaveAs(os.path.abspath(pdf_path), FileFormat=17)  # FileFormat 17 represents PDF\n",
    "    finally:\n",
    "        doc.Close()\n",
    "        word.Quit()\n",
    "    os.remove(temp_doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313e160-babc-4e3a-ae3d-882f3fbc5982",
   "metadata": {},
   "source": [
    "Function to read the text from .pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa58df7e-3c2d-4ed2-b4c0-ef3433409bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        extracted_text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            extracted_text += page.extract_text()\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee3a97-1b7c-4386-b390-90312512944e",
   "metadata": {},
   "source": [
    "Saving all the .docx files to .pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a13bae-685e-4f31-b73d-57a54eb776c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(os.listdir(input_path)):\n",
    "    if file.endswith('.docx'):\n",
    "        name = file[:-5]\n",
    "        name = f'{name}.pdf'\n",
    "        save_to_pdf(docx_path=f'{input_path}/{file}', pdf_path=f'{output_path}/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f294f18-3f7c-4057-880c-1f2e827c888b",
   "metadata": {},
   "source": [
    "Initializing a blank dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59530ba3-0a83-4498-876e-4e0b570b68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Heading', 'Content'])\n",
    "test = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498abf36-05b8-49bc-ab6d-09a14a5f1f3b",
   "metadata": {},
   "source": [
    "Define the headings of the legal documents in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc15a2c-34bc-4225-87c5-cc3d9058f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = [\n",
    "    \"Employment Agreement\", \n",
    "    \"Investment Commitment Agreement\", \n",
    "    \"Consulting Agreement\", \n",
    "    \"Contract for the sale of goods\", \n",
    "    \"Joint Venture Agreement\",\n",
    "    \"Shareholder's Agreement\",\n",
    "    \"Shareholder's Agreement\",\n",
    "    \"Founders Agreement\", \n",
    "    \"Limited Liability Operating Agreement\",\n",
    "    \"Offer Letter Agreement\",\n",
    "    \"Collaboration Agreement\",\n",
    "    \"Rental Agreement\",\n",
    "    \"Sale Agreement\",\n",
    "    \"Agreement\"\n",
    "]\n",
    "\n",
    "test_headings = [\n",
    "    \"Joint Venture Agreement\",\n",
    "    \"Shareholder's Agreement\",\n",
    "    \"Founders Agreement\",\n",
    "    \"Sale Agreement\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236a6f8-74a9-4931-9b85-5b0a326fa5ec",
   "metadata": {},
   "source": [
    "Extract text from all the files and store it in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b3db7-9a9e-4f65-80ca-22c06914833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(os.listdir(output_path)):\n",
    "    if file.endswith('.pdf'):\n",
    "        row = []\n",
    "        content = read_text_from_pdf(f'{output_path}/{file}')\n",
    "        row = [headings[index], content]\n",
    "        df.loc[index] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc14f17c-257b-4c94-8d30-62774a90bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(os.listdir(f'../{testing_path}')):\n",
    "    if file.endswith('.pdf'):\n",
    "        row = []\n",
    "        content = read_text_from_pdf(f'../{testing_path}/{file}')\n",
    "        row = [headings[index], content]\n",
    "        test.loc[index] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2775d2c7-a4d4-4181-9d1f-995953ace01b",
   "metadata": {},
   "source": [
    "Save the dataframes to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaaeaae-1331-4580-8019-7026428616c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de977229-0803-4547-98fd-52c012c2849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9875cb38-3816-4e5f-bc84-e1a6796ab883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6311fe-c8cb-4690-862b-6f5c27e0c133",
   "metadata": {},
   "source": [
    "Load the column 'contents' to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aeb7c48-602c-4155-baa6-9b7b990cfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = df['Content']\n",
    "test_content = test['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc56a28-73dc-478f-9f23-018cf0f1ac70",
   "metadata": {},
   "source": [
    "The clauses are defined in the form of (x) or x.y.z. where x, y, z are numbers.\n",
    "Therefore, the delimiters are defined as such with the required regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60a4eb05-46aa-44ec-83ed-f4d0fca669f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiters = [\n",
    "    r'\\(\\d+\\)',     \n",
    "    r'\\d+\\.\\d+\\.\\d+' \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8442f4-48bf-4d37-9771-94a765fbb6af",
   "metadata": {},
   "source": [
    "Function to extract the clauses from content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a87fe10-3f89-4dfa-9bd1-bea714bf360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clauses(content):\n",
    "    clauses = []\n",
    "    current_clause = ''\n",
    "    for row in content:\n",
    "        for line in row.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if any(re.match(delimiter, line) for delimiter in delimiters):\n",
    "                if current_clause:\n",
    "                    clauses.append(current_clause.strip())\n",
    "                    current_clause = ''\n",
    "            current_clause += line + ' '\n",
    "        if current_clause:\n",
    "            clauses.append(current_clause.strip())\n",
    "    return clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbb2b242-97ed-4d7c-a2bd-f7bc7525de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clauses = get_clauses(content)\n",
    "test_clauses = get_clauses(test_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483e2ae-331f-46e1-b7b1-0cf8f98cd70e",
   "metadata": {},
   "source": [
    "Doc2Vec embeddings requires tagged documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4d40f2f-7618-4b7a-ac8c-171764ade7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = {}\n",
    "for index, doc in enumerate(clauses):\n",
    "    key = f\"DOC_{index+1}\"\n",
    "    tagged[key] = TaggedDocument(words=doc, tags=[f\"DOC_{index+1}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3d8a5b1-4108-4c1d-b459-906e084f3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for key in tagged:\n",
    "    docs.append(tagged[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd3619-7597-48e9-bdc8-76a6ec5cac26",
   "metadata": {},
   "source": [
    "Initializing a Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef76fecd-a9cc-490e-8c74-770058587c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 300\n",
    "doc2vec = Doc2Vec(documents=docs, vector_size=dim, window=10, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcbc80-48ac-4a18-aca6-083e818f99c8",
   "metadata": {},
   "source": [
    "Saving the embeddings and creating an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4917b5d8-453e-4a14-8f4b-66691de0b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = doc2vec.dv\n",
    "embeddings.save('embeddings')\n",
    "emb = embeddings.vectors\n",
    "embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(emb), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de57b0a3-8856-44c9-9cbb-0e2ca3ed0924",
   "metadata": {},
   "source": [
    "Initializing the GPT2-XL transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f883120f-5428-4f88-8614-ceb9efb18510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-xl\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0562fce4-c924-4207-ba0b-f2a3f7f9d43f",
   "metadata": {},
   "source": [
    "Model structure before adding the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1d9860e-afd2-4af8-94c1-5d83a198c897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1600)\n",
       "    (wpe): Embedding(1024, 1600)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-47): 48 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba423b91-1fea-4783-a604-4fe018d737b3",
   "metadata": {},
   "source": [
    "Model Structure after adding the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9ca8265-e923-47a7-b1cb-583ee0c6f1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1600)\n",
       "    (wpe): Embedding(1024, 1600)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-47): 48 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
       "  (embeddings): Embedding(665, 300)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings = embedding_layer\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a9aa4-712e-4974-aba1-affa7089c3ee",
   "metadata": {},
   "source": [
    "Initialize a custom dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b562b6b5-33b7-4e03-a96d-ad21be9f8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.data[idx]\n",
    "        input_ids = self.tokenizer.encode(input_text, add_special_tokens=True)\n",
    "        return torch.tensor(input_ids[:-1]), torch.tensor(input_ids[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097db3d3-6d39-4a75-8fab-81d095fd0e4a",
   "metadata": {},
   "source": [
    "Create train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a67d0f2d-83f0-4308-b036-cd6ef7f720af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(clauses[:1024], tokenizer)\n",
    "valid_dataset = CustomDataset(test_clauses[:1024], tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4e90c-c59b-4be7-90c0-e1b73c3c86fe",
   "metadata": {},
   "source": [
    "Set the device to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2653ec37-6796-4a5f-9309-3f080b94569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec35043d-cc98-485d-9bad-145166e2cfbb",
   "metadata": {},
   "source": [
    "Define the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fa8178a-41e5-4439-b7c4-9f15a422b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e5cf54c-02de-40b3-b6dd-6b6a3eb96c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6329 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m      9\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1043\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1043\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1058\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:831\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    830\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwte(input_ids)\n\u001b[1;32m--> 831\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    832\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(5):\n",
    "    for batch in train_loader:\n",
    "        input_ids, labels = batch[:1024]\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "        for batch in valid_loader:\n",
    "            input_ids, labels = batch[:1024]\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(input_ids, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item() * input_ids.size(0)\n",
    "            total_samples += input_ids.size(0)\n",
    "        avg_loss = total_loss / total_samples\n",
    "        print(f\"Validation Loss: {avg_loss}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8021feeb-fe63-4289-9c1f-0e7faabb3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./clause-model\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
