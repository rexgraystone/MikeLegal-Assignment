{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d00e5dc-0a44-4298-9168-0fd8bf2c3bf3",
   "metadata": {},
   "source": [
    "# Task - Generate Missing Clauses from Legal Contracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2548e170-dfaa-403d-8612-6ac031a3a403",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a66899e-a664-42ea-a6c7-af854cfafd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "import win32com.client as win32\n",
    "import PyPDF2\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd96dd-50f0-435b-83d0-1d2df5c47de2",
   "metadata": {},
   "source": [
    "Define the required paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a0b26a-e66f-420d-ab43-a85a6078ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../SampleDocs'\n",
    "output_path = '../PDFs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c24b70-44f1-4169-a616-12ebf2979704",
   "metadata": {},
   "source": [
    "Function to save the .docx files to .pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07bed8e6-c006-47d1-939b-7d795ac185a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pdf(docx_path, pdf_path):\n",
    "    doc = Document(docx_path)\n",
    "    temp_doc_path = \"temp.doc\"\n",
    "    doc.save(temp_doc_path)\n",
    "    word = win32.Dispatch(\"Word.Application\")\n",
    "    try:\n",
    "        word.Visible = False\n",
    "        doc = word.Documents.Open(os.path.abspath(temp_doc_path))\n",
    "        doc.SaveAs(os.path.abspath(pdf_path), FileFormat=17)  # FileFormat 17 represents PDF\n",
    "    finally:\n",
    "        doc.Close()\n",
    "        word.Quit()\n",
    "    os.remove(temp_doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313e160-babc-4e3a-ae3d-882f3fbc5982",
   "metadata": {},
   "source": [
    "Function to read the text from .pdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa58df7e-3c2d-4ed2-b4c0-ef3433409bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        extracted_text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            extracted_text += page.extract_text()\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee3a97-1b7c-4386-b390-90312512944e",
   "metadata": {},
   "source": [
    "Saving all the .docx files to .pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a13bae-685e-4f31-b73d-57a54eb776c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(os.listdir(input_path)):\n",
    "    if file.endswith('.docx'):\n",
    "        name = file[:-5]\n",
    "        name = f'{name}.pdf'\n",
    "        save_to_pdf(docx_path=f'{input_path}/{file}', pdf_path=f'{output_path}/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f294f18-3f7c-4057-880c-1f2e827c888b",
   "metadata": {},
   "source": [
    "Initializing a blank dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59530ba3-0a83-4498-876e-4e0b570b68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Heading', 'Content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498abf36-05b8-49bc-ab6d-09a14a5f1f3b",
   "metadata": {},
   "source": [
    "Define the headings of the legal documents in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afc15a2c-34bc-4225-87c5-cc3d9058f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = [\n",
    "    \"Employment Agreement\", \n",
    "    \"Investment Commitment Agreement\", \n",
    "    \"Consulting Agreement\", \n",
    "    \"Contract for the sale of goods\", \n",
    "    \"Joint Venture Agreement\",\n",
    "    \"Shareholder's Agreement\",\n",
    "    \"Shareholder's Agreement\",\n",
    "    \"Founders Agreement\", \n",
    "    \"Limited Liability Operating Agreement\",\n",
    "    \"Offer Letter Agreement\",\n",
    "    \"Collaboration Agreement\",\n",
    "    \"Rental Agreement\",\n",
    "    \"Sale Agreement\",\n",
    "    \"Agreement\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236a6f8-74a9-4931-9b85-5b0a326fa5ec",
   "metadata": {},
   "source": [
    "Extract text from all the files and store it in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b72b3db7-9a9e-4f65-80ca-22c06914833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(os.listdir(output_path)):\n",
    "    if file.endswith('.pdf'):\n",
    "        row = []\n",
    "        content = read_text_from_pdf(f'{output_path}/{file}')\n",
    "        row = [headings[index], content]\n",
    "        df.loc[index] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2775d2c7-a4d4-4181-9d1f-995953ace01b",
   "metadata": {},
   "source": [
    "Save the dataframe to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9875cb38-3816-4e5f-bc84-e1a6796ab883",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6311fe-c8cb-4690-862b-6f5c27e0c133",
   "metadata": {},
   "source": [
    "Load the column 'contents' to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aeb7c48-602c-4155-baa6-9b7b990cfe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = df['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc56a28-73dc-478f-9f23-018cf0f1ac70",
   "metadata": {},
   "source": [
    "The clauses are defined in the form of (x) or x.y.z. where x, y, z are numbers.\n",
    "Therefore, the delimiters are defined as such with the required regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60a4eb05-46aa-44ec-83ed-f4d0fca669f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiters = [\n",
    "    r'\\(\\d+\\)',     \n",
    "    r'\\d+\\.\\d+\\.\\d+' \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8442f4-48bf-4d37-9771-94a765fbb6af",
   "metadata": {},
   "source": [
    "Function to extract the clauses from content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a87fe10-3f89-4dfa-9bd1-bea714bf360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clauses(content):\n",
    "    clauses = []\n",
    "    current_clause = ''\n",
    "    for row in content:\n",
    "        for line in row.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if any(re.match(delimiter, line) for delimiter in delimiters):\n",
    "                if current_clause:\n",
    "                    clauses.append(current_clause.strip())\n",
    "                    current_clause = ''\n",
    "            current_clause += line + ' '\n",
    "        if current_clause:\n",
    "            clauses.append(current_clause.strip())\n",
    "    return clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbb2b242-97ed-4d7c-a2bd-f7bc7525de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clauses = get_clauses(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483e2ae-331f-46e1-b7b1-0cf8f98cd70e",
   "metadata": {},
   "source": [
    "Doc2Vec embeddings requires tagged documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4d40f2f-7618-4b7a-ac8c-171764ade7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = {}\n",
    "for index, doc in enumerate(clauses):\n",
    "    key = f\"DOC_{index+1}\"\n",
    "    tagged[key] = TaggedDocument(words=doc, tags=[f\"DOC_{index+1}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3d8a5b1-4108-4c1d-b459-906e084f3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for key in tagged:\n",
    "    docs.append(tagged[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd3619-7597-48e9-bdc8-76a6ec5cac26",
   "metadata": {},
   "source": [
    "Initializing a Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef76fecd-a9cc-490e-8c74-770058587c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 300\n",
    "doc2vec = Doc2Vec(documents=docs, vector_size=dim, window=10, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcbc80-48ac-4a18-aca6-083e818f99c8",
   "metadata": {},
   "source": [
    "Saving the embeddings and creating an embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4917b5d8-453e-4a14-8f4b-66691de0b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = doc2vec.dv\n",
    "embeddings.save('embeddings')\n",
    "emb = embeddings.vectors\n",
    "embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(emb), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de57b0a3-8856-44c9-9cbb-0e2ca3ed0924",
   "metadata": {},
   "source": [
    "Initializing the GPT2-XL transformers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f883120f-5428-4f88-8614-ceb9efb18510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-xl\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0562fce4-c924-4207-ba0b-f2a3f7f9d43f",
   "metadata": {},
   "source": [
    "Model structure before adding the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c1d9860e-afd2-4af8-94c1-5d83a198c897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1600)\n",
       "    (wpe): Embedding(1024, 1600)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-47): 48 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba423b91-1fea-4783-a604-4fe018d737b3",
   "metadata": {},
   "source": [
    "Model Structure after adding the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2337b1b-5a86-4b51-84df-6f537cc34aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1600)\n",
       "    (wpe): Embedding(1024, 1600)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-47): 48 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1600,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1600, out_features=50257, bias=False)\n",
       "  (embeddings): Embedding(420, 300)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings = embedding_layer\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fa03a6db-fbb7-46b6-b6c5-61a22605bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = clauses[0]\n",
    "max_new_tokens = 512\n",
    "sample = sample[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "25dcb6b4-ba20-4210-9fb8-5853f99a2c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(sample, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "51ae9ad9-122a-4610-80da-3216993840ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_new_tokens=max_new_tokens, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "80d67883-aedd-4293-a92b-6be31c22e03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singhania & Partners LLP     Draft for Discussion 29th October, 2020   Privileged and confidential Employment  Agreement   Attorney work product Page 1 of 21   EMPLOYMENT AGREEMENT  Singhania & Partners LLP     Draft for Discussion 29th October, 2020   Privileged and confidential Employment  Agreement   Attorney work product Page 2 of 21 INDEX  1. DEFINITIONS AND INTERPRETATION .........................................................................................  4 2. EMPLOYMENT.....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n"
     ]
    }
   ],
   "source": [
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
